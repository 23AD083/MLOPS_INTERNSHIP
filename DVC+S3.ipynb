{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23AD083/MLOPS_INTERNSHIP/blob/main/DVC%2BS3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRY8Y5GvwOb3"
      },
      "source": [
        "# GitHub + Google Colab + DVC (with Amazon S3 Storage)\n",
        "\n",
        "This notebook provides a comprehensive guide to setting up and using DVC (Data Version Control) with Google Colab and Amazon S3 as the remote storage. This combination is ideal for scalable and reproducible machine learning experiments in a cloud environment.\n",
        "\n",
        "## Prerequisites for Amazon S3\n",
        "\n",
        "Before starting, you need to set up your AWS account:\n",
        "\n",
        "1.  **AWS Account:** You must have an active AWS account.\n",
        "2.  **S3 Bucket:** Create an S3 bucket in your chosen AWS region (e.g., `us-east-1`, `ap-south-1`). This bucket will be your DVC remote storage. Make sure the bucket name is globally unique.\n",
        "3.  **IAM User with Permissions:** It's highly recommended to create a dedicated IAM (Identity and Access Management) user for DVC with programmatic access.\n",
        "    * Go to IAM -> Users -> Add user.\n",
        "    * Give it a name (e.g., `dvc-colab-user`).\n",
        "    * Select \"Access key - Programmatic access\" as the credential type.\n",
        "    * For permissions, attach an existing policy directly. **Create a custom policy** that grants access *only* to your specific S3 bucket. A minimal policy would look like this (replace `your-dvc-bucket-name` with your actual bucket name):\n",
        "\n",
        "    ```json\n",
        "    {\n",
        "        \"Version\": \"2012-10-17\",\n",
        "        \"Statement\": [\n",
        "            {\n",
        "                \"Effect\": \"Allow\",\n",
        "                \"Action\": [\n",
        "                    \"s3:ListBucket\",\n",
        "                    \"s3:GetObject\",\n",
        "                    \"s3:PutObject\",\n",
        "                    \"s3:DeleteObject\",\n",
        "                    \"s3:HeadBucket\"\n",
        "                ],\n",
        "                \"Resource\": [\n",
        "                    \"arn:aws:s3:::your-dvc-bucket-name\",\n",
        "                    \"arn:aws:s3:::your-dvc-bucket-name/*\"\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    ```\n",
        "    * Review and create the user. **Crucially, save the Access Key ID and Secret Access Key when they are displayed.** You will not be able to retrieve the Secret Access Key again. Treat these as highly sensitive credentials.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzOC4L-wOb9"
      },
      "source": [
        "## Hands-On Coding Examples (with Amazon S3)\n",
        "\n",
        "Let's set up our environment and perform DVC operations using Amazon S3.\n",
        "\n",
        "### Setting Up the Environment\n",
        "\n",
        "First, we need to install DVC, the AWS CLI, and configure our AWS credentials in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acZ8_wmpwOb-",
        "outputId": "c16cd714-aa3a-4eea-889e-059846c283f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.41.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting dvc[s3]\n",
            "  Downloading dvc-3.61.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (25.3.0)\n",
            "Collecting celery (from dvc[s3])\n",
            "  Downloading celery-5.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting colorama>=0.3.9 (from dvc[s3])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting configobj>=5.0.9 (from dvc[s3])\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: distro>=1.3 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (1.9.0)\n",
            "Collecting dpath<3,>=2.1.0 (from dvc[s3])\n",
            "  Downloading dpath-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting dulwich (from dvc[s3])\n",
            "  Downloading dulwich-0.23.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting dvc-data<3.17,>=3.16.2 (from dvc[s3])\n",
            "  Downloading dvc_data-3.16.10-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting dvc-http>=2.29.0 (from dvc[s3])\n",
            "  Downloading dvc_http-2.32.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting dvc-objects (from dvc[s3])\n",
            "  Downloading dvc_objects-5.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dvc-render<2,>=1.0.1 (from dvc[s3])\n",
            "  Downloading dvc_render-1.0.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dvc-studio-client<1,>=0.21 (from dvc[s3])\n",
            "  Downloading dvc_studio_client-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting dvc-task<1,>=0.3.0 (from dvc[s3])\n",
            "  Downloading dvc_task-0.40.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting flatten_dict<1,>=0.4.1 (from dvc[s3])\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting flufl.lock<9,>=8.1.0 (from dvc[s3])\n",
            "  Downloading flufl_lock-8.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: fsspec>=2024.2.0 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (2025.3.2)\n",
            "Collecting funcy>=1.14 (from dvc[s3])\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting grandalf<1,>=0.7 (from dvc[s3])\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting gto<2,>=1.6.0 (from dvc[s3])\n",
            "  Downloading gto-1.7.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting hydra-core>=1.1 (from dvc[s3])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iterative-telemetry>=0.0.7 (from dvc[s3])\n",
            "  Downloading iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting kombu (from dvc[s3])\n",
            "  Downloading kombu-5.5.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (3.5)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (2.3.0)\n",
            "Requirement already satisfied: packaging>=19 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (24.2)\n",
            "Collecting pathspec>=0.10.3 (from dvc[s3])\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (4.3.8)\n",
            "Requirement already satisfied: psutil>=5.8 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (5.9.5)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (3.0.4)\n",
            "Collecting pygtrie>=2.3.2 (from dvc[s3])\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (3.2.3)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (2.32.3)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (13.9.4)\n",
            "Collecting ruamel.yaml>=0.17.11 (from dvc[s3])\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting scmrepo<4,>=3.3.8 (from dvc[s3])\n",
            "  Downloading scmrepo-3.3.11-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting shortuuid>=0.5 (from dvc[s3])\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting shtab<2,>=1.3.4 (from dvc[s3])\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (0.9.0)\n",
            "Requirement already satisfied: tomlkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (0.13.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.63.1 in /usr/local/lib/python3.11/dist-packages (from dvc[s3]) (4.67.1)\n",
            "Collecting voluptuous>=0.11.7 (from dvc[s3])\n",
            "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting zc.lockfile>=1.2.1 (from dvc[s3])\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting dvc-s3<4,>=3.2.1 (from dvc[s3])\n",
            "  Downloading dvc_s3-3.2.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting botocore==1.39.4 (from awscli)\n",
            "  Downloading botocore-1.39.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting docutils<=0.19,>=0.18.1 (from awscli)\n",
            "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from awscli)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.11/dist-packages (from awscli) (6.0.2)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.39.4->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore==1.39.4->awscli) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore==1.39.4->awscli) (2.4.0)\n",
            "Collecting dictdiffer>=0.8.1 (from dvc-data<3.17,>=3.16.2->dvc[s3])\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting diskcache>=5.2.1 (from dvc-data<3.17,>=3.16.2->dvc[s3])\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sqltrie<1,>=0.11.0 (from dvc-data<3.17,>=3.16.2->dvc[s3])\n",
            "  Downloading sqltrie-0.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: orjson<4,>=3 in /usr/local/lib/python3.11/dist-packages (from dvc-data<3.17,>=3.16.2->dvc[s3]) (3.10.18)\n",
            "Collecting aiohttp-retry>=2.5.0 (from dvc-http>=2.29.0->dvc[s3])\n",
            "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting s3fs>=2024.12.0 (from dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading s3fs-2025.5.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting aiobotocore>=2.5.0 (from aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading aiobotocore-2.23.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting billiard<5.0,>=4.2.1 (from celery->dvc[s3])\n",
            "  Downloading billiard-4.2.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting vine<6.0,>=5.1.0 (from celery->dvc[s3])\n",
            "  Downloading vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0,>=8.1.2 in /usr/local/lib/python3.11/dist-packages (from celery->dvc[s3]) (8.2.1)\n",
            "Collecting click-didyoumean>=0.3.0 (from celery->dvc[s3])\n",
            "  Downloading click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting click-repl>=0.2.0 (from celery->dvc[s3])\n",
            "  Downloading click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting click-plugins>=1.1.1 (from celery->dvc[s3])\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: six<2.0,>=1.12 in /usr/local/lib/python3.11/dist-packages (from flatten_dict<1,>=0.4.1->dvc[s3]) (1.17.0)\n",
            "Requirement already satisfied: atpublic in /usr/local/lib/python3.11/dist-packages (from flufl.lock<9,>=8.1.0->dvc[s3]) (5.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc[s3]) (0.4)\n",
            "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc[s3]) (2.11.7)\n",
            "Collecting semver>=2.13.0 (from gto<2,>=1.6.0->dvc[s3])\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gto<2,>=1.6.0->dvc[s3]) (0.16.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->dvc[s3]) (4.9.3)\n",
            "Collecting appdirs (from iterative-telemetry>=0.0.7->dvc[s3])\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from iterative-telemetry>=0.0.7->dvc[s3]) (3.18.0)\n",
            "Collecting amqp<6.0.0,>=5.1.1 (from kombu->dvc[s3])\n",
            "  Downloading amqp-5.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tzdata>=2025.2 in /usr/local/lib/python3.11/dist-packages (from kombu->dvc[s3]) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc[s3]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc[s3]) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->dvc[s3]) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->dvc[s3]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->dvc[s3]) (2.19.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.11->dvc[s3])\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: gitpython>3 in /usr/local/lib/python3.11/dist-packages (from scmrepo<4,>=3.3.8->dvc[s3]) (3.1.44)\n",
            "Requirement already satisfied: pygit2>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from scmrepo<4,>=3.3.8->dvc[s3]) (1.18.0)\n",
            "Collecting asyncssh<3,>=2.13.1 (from scmrepo<4,>=3.3.8->dvc[s3])\n",
            "  Downloading asyncssh-2.21.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zc.lockfile>=1.2.1->dvc[s3]) (75.2.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.2 in /usr/local/lib/python3.11/dist-packages (from aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (3.11.15)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting aiobotocore>=2.5.0 (from aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading aiobotocore-2.22.0-py3-none-any.whl.metadata (24 kB)\n",
            "  Downloading aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
            "  Downloading aiobotocore-2.21.0-py3-none-any.whl.metadata (24 kB)\n",
            "  Downloading aiobotocore-2.20.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.19.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.18.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.17.0-py3-none-any.whl.metadata (23 kB)\n",
            "INFO: pip is still looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading aiobotocore-2.16.1-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.16.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.15.2-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.15.1-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.15.0-py3-none-any.whl.metadata (23 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading aiobotocore-2.14.0-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading aiobotocore-2.13.3-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading aiobotocore-2.13.2-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading aiobotocore-2.13.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading aiobotocore-2.13.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.12.4-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.12.3-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.12.2-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.12.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.11.2-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.11.1-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.11.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading aiobotocore-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading aiobotocore-2.9.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading aiobotocore-2.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading aiobotocore-2.8.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading aiobotocore-2.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading aiobotocore-2.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading aiobotocore-2.5.4-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading aiobotocore-2.5.3-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading aiobotocore-2.5.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading aiobotocore-2.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading aiobotocore-2.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dvc-s3<4,>=3.2.1 (from dvc[s3])\n",
            "  Downloading dvc_s3-3.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.41.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.39.3 (from awscli)\n",
            "  Downloading botocore-1.39.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.41.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.39.2 (from awscli)\n",
            "  Downloading botocore-1.39.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.41.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.39.1 (from awscli)\n",
            "  Downloading botocore-1.39.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.41.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.39.0 (from awscli)\n",
            "  Downloading botocore-1.39.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.45-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.46 (from awscli)\n",
            "  Downloading botocore-1.38.46-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.44-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.45 (from awscli)\n",
            "  Downloading botocore-1.38.45-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.43-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.44 (from awscli)\n",
            "  Downloading botocore-1.38.44-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.42-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.43 (from awscli)\n",
            "  Downloading botocore-1.38.43-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.41-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.42 (from awscli)\n",
            "  Downloading botocore-1.38.42-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.40-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.41 (from awscli)\n",
            "  Downloading botocore-1.38.41-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.39-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.40 (from awscli)\n",
            "  Downloading botocore-1.38.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.38-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.39 (from awscli)\n",
            "  Downloading botocore-1.38.39-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.37-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.38 (from awscli)\n",
            "  Downloading botocore-1.38.38-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.36-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.37 (from awscli)\n",
            "  Downloading botocore-1.38.37-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.35-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.36 (from awscli)\n",
            "  Downloading botocore-1.38.36-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.34-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.35 (from awscli)\n",
            "  Downloading botocore-1.38.35-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.33-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.34 (from awscli)\n",
            "  Downloading botocore-1.38.34-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.32-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.33 (from awscli)\n",
            "  Downloading botocore-1.38.33-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.31-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.32 (from awscli)\n",
            "  Downloading botocore-1.38.32-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.30-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.31 (from awscli)\n",
            "  Downloading botocore-1.38.31-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.29-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.30 (from awscli)\n",
            "  Downloading botocore-1.38.30-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.28-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.29 (from awscli)\n",
            "  Downloading botocore-1.38.29-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.27-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.28 (from awscli)\n",
            "  Downloading botocore-1.38.28-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.40.26-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.38.27 (from awscli)\n",
            "  Downloading botocore-1.38.27-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (6.6.3)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (1.17.2)\n",
            "Collecting boto3<1.38.28,>=1.38.23 (from aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading boto3-1.38.27-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: cryptography>=39.0 in /usr/local/lib/python3.11/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.3.8->dvc[s3]) (43.0.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.3.8->dvc[s3]) (4.14.1)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.36 in /usr/local/lib/python3.11/dist-packages (from click-repl>=0.2.0->celery->dvc[s3]) (3.0.51)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>3->scmrepo<4,>=3.3.8->dvc[s3]) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12->dvc[s3]) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[s3]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[s3]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc[s3]) (0.4.1)\n",
            "Requirement already satisfied: cffi>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc[s3]) (1.17.1)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.12.0 (from dvc-s3<4,>=3.2.1->dvc[s3])\n",
            "  Downloading s3fs-2025.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc[s3]) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (1.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore>=2.5.0->aiobotocore[boto3]>=2.5.0->dvc-s3<4,>=3.2.1->dvc[s3]) (1.20.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.17.0->pygit2>=1.14.0->scmrepo<4,>=3.3.8->dvc[s3]) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.3.8->dvc[s3]) (5.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc[s3]) (0.2.13)\n",
            "Downloading awscli-1.40.26-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.27-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dpath-2.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading dvc_data-3.16.10-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dvc_http-2.32.0-py3-none-any.whl (12 kB)\n",
            "Downloading dvc_objects-5.1.1-py3-none-any.whl (33 kB)\n",
            "Downloading dvc_render-1.0.2-py3-none-any.whl (22 kB)\n",
            "Downloading dvc_s3-3.2.2-py3-none-any.whl (13 kB)\n",
            "Downloading aiobotocore-2.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dvc_studio_client-0.21.0-py3-none-any.whl (16 kB)\n",
            "Downloading dvc_task-0.40.2-py3-none-any.whl (21 kB)\n",
            "Downloading celery-5.5.3-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.8/438.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Downloading flufl_lock-8.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gto-1.7.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
            "Downloading kombu-5.5.4-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scmrepo-3.3.11-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dulwich-0.23.2-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
            "Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Downloading dvc-3.61.0-py3-none-any.whl (461 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m461.0/461.0 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading amqp-5.3.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncssh-2.21.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading billiard-4.2.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3fs-2025.3.2-py3-none-any.whl (30 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading sqltrie-0.11.2-py3-none-any.whl (17 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading boto3-1.38.27-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygtrie, funcy, dictdiffer, appdirs, zc.lockfile, voluptuous, vine, sqltrie, shtab, shortuuid, semver, ruamel.yaml.clib, rsa, pathspec, jmespath, grandalf, flufl.lock, flatten_dict, dvc-render, dvc-objects, dulwich, dpath, docutils, diskcache, configobj, colorama, click-plugins, click-didyoumean, billiard, aioitertools, ruamel.yaml, iterative-telemetry, hydra-core, dvc-studio-client, dvc-data, click-repl, botocore, amqp, s3transfer, kombu, asyncssh, aiohttp-retry, aiobotocore, scmrepo, s3fs, dvc-http, celery, boto3, awscli, gto, dvc-task, dvc, dvc-s3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiobotocore-2.23.0 aiohttp-retry-2.9.1 aioitertools-0.12.0 amqp-5.3.1 appdirs-1.4.4 asyncssh-2.21.0 awscli-1.40.26 billiard-4.2.1 boto3-1.38.27 botocore-1.38.27 celery-5.5.3 click-didyoumean-0.3.1 click-plugins-1.1.1.2 click-repl-0.3.0 colorama-0.4.6 configobj-5.0.9 dictdiffer-0.9.0 diskcache-5.6.3 docutils-0.19 dpath-2.2.0 dulwich-0.23.2 dvc-3.61.0 dvc-data-3.16.10 dvc-http-2.32.0 dvc-objects-5.1.1 dvc-render-1.0.2 dvc-s3-3.2.2 dvc-studio-client-0.21.0 dvc-task-0.40.2 flatten_dict-0.4.2 flufl.lock-8.2.0 funcy-2.0 grandalf-0.8 gto-1.7.2 hydra-core-1.3.2 iterative-telemetry-0.0.10 jmespath-1.0.1 kombu-5.5.4 pathspec-0.12.1 pygtrie-2.5.0 rsa-4.7.2 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 s3fs-2025.3.2 s3transfer-0.13.0 scmrepo-3.3.11 semver-3.0.4 shortuuid-1.0.13 shtab-1.7.2 sqltrie-0.11.2 vine-5.1.0 voluptuous-0.15.2 zc.lockfile-3.0.post1\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install DVC with S3 support and AWS CLI\n",
        "# We specifically install 'dvc[s3]' for S3 integration.\n",
        "# awscli is the AWS Command Line Interface which DVC will use for authentication.\n",
        "!pip install dvc[s3] awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ox6xkQchwOcB",
        "outputId": "be9c67d7-628e-4b19-e7d6-463ed2fa021a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1517707159.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# and retrieve them like: os.environ['AWS_ACCESS_KEY_ID']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AWS_ACCESS_KEY_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter your AWS Access Key ID: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AWS_SECRET_ACCESS_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter your AWS Secret Access Key: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Set your desired AWS region (e.g., 'us-east-1', 'ap-south-1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Cell 2: Configure AWS Credentials\n",
        "# We will set AWS credentials as environment variables for the Colab session.\n",
        "# DO NOT hardcode these in a public notebook.\n",
        "# In a real project, use Colab's \"Secrets\" feature or AWS Secrets Manager.\n",
        "# For this tutorial, we'll use input() for demonstration purposes.\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Prompt for AWS credentials\n",
        "# For production, consider using Colab's \"Secrets\" feature (Tools -> Secrets)\n",
        "# and retrieve them like: os.environ['AWS_ACCESS_KEY_ID']\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = getpass.getpass('Enter your AWS Access Key ID: ')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = getpass.getpass('Enter your AWS Secret Access Key: ')\n",
        "\n",
        "# Set your desired AWS region (e.g., 'us-east-1', 'ap-south-1')\n",
        "# This should match the region where your S3 bucket is located.\n",
        "AWS_REGION = 'us-east-1' # Example region, change this to your bucket's region\n",
        "os.environ['AWS_DEFAULT_REGION'] = AWS_REGION\n",
        "\n",
        "print(f\"AWS credentials and region '{AWS_REGION}' configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKS4ioe9wOcC",
        "outputId": "ef46f760-3726-4d0d-88b8-c8a794c61700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name                    Value             Type    Location\n",
            "      ----                    -----             ----    --------\n",
            "   profile                <not set>             None    None\n",
            "access_key     ****************HCU2              env    \n",
            "secret_key     ****************5x4U              env    \n",
            "    region                us-east-1              env    AWS_DEFAULT_REGION\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Verify AWS CLI configuration (optional, but good for debugging)\n",
        "!aws configure list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-a1WyrYwOcC",
        "outputId": "4f8c69af-2ec9-4986-b4a6-90a8cba07259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/dvc_s3_colab_project\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Create and navigate to our project directory\n",
        "# We'll work in /content/ for this example as we don't need Google Drive mounting.\n",
        "%cd /content/\n",
        "%mkdir -p dvc_s3_colab_project\n",
        "%cd dvc_s3_colab_project="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq8ZD_A2wOcD"
      },
      "source": [
        "### Initializing Git and DVC\n",
        "\n",
        "Now, let's initialize a Git repository and DVC within our project directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUeUnZMHwOcE",
        "outputId": "b3cc8aaf-a599-4e6b-8bbe-c85d3518d27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/dvc_s3_colab_project/.git/\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Initialize Git repository\n",
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs26VfagwOcF",
        "outputId": "a71ff331-65f1-4c04-cf8e-b81ac393229f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR\u001b[39m: failed to initiate DVC - '.dvc' exists. Use `-f` to force.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Cell 6: Initialize DVC\n",
        "!dvc init --no-scm\n",
        "# Again, --no-scm because Colab's Git isn't fully integrated in the way DVC expects initially.\n",
        "# We'll manually add .dvc files to git."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXYWZQQswOcF",
        "outputId": "f8cefac5-bc42-4a0f-8bed-cadbb57f3bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting 's3_remote' as a default remote.\n",
            "\u001b[31mERROR\u001b[39m: configuration error - config file error: remote 's3_remote' already exists. Use `-f|--force` to overwrite it.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Cell 7: Configure DVC remote to Amazon S3\n",
        "# REPLACE 'your-dvc-s3-bucket' with the name of YOUR S3 bucket\n",
        "# Optionally, you can add a path within the bucket: s3://your-dvc-s3-bucket/dvc_data/\n",
        "S3_BUCKET_NAME = 's3-dvc-buck' # <--- IMPORTANT: Replace with your actual S3 bucket name\n",
        "!dvc remote add -d s3_remote s3://{S3_BUCKET_NAME}/dvc_data_store/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"codeboosterstech@gmail.com\"\n",
        "!git config --global user.name \"codeboosterstech\""
      ],
      "metadata": {
        "id": "mLJcZbuq1WV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD8Ngsi3wOcF",
        "outputId": "a2d8133b-4443-40d8-bb6f-ed8600055f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.dvc/cache/\u001b[m\n",
            "\t\u001b[31m.dvc/tmp/\u001b[m\n",
            "\t\u001b[31mmy_s3_dataset.csv\u001b[m\n",
            "\t\u001b[31mmy_s3_dataset.csv.dvc\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Add and commit DVC configuration files to Git\n",
        "!git add .dvc/config .dvcignore\n",
        "!git commit -m \"Initialize Git and DVC for S3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5nJqIe1wOcG"
      },
      "source": [
        "### Tracking Data with DVC\n",
        "\n",
        "Let's create a dummy dataset and track it with DVC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlxpiwDwwOcG",
        "outputId": "0bc55693-58c7-4db7-c980-83b1757620cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'my_s3_dataset.csv' created.\n",
            "total 8.0K\n",
            "-rw-r--r-- 1 root root 3.9K Jul 11 00:17 my_s3_dataset.csv\n",
            "-rw-r--r-- 1 root root   97 Jul 11 00:15 my_s3_dataset.csv.dvc\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Create a dummy dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a simple DataFrame\n",
        "data = {\n",
        "    'feature1': np.random.rand(100),\n",
        "    'feature2': np.random.randint(0, 10, 100),\n",
        "    'target': np.random.rand(100) * 10\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "DATA_FILE_NAME = 'my_s3_dataset.csv'\n",
        "df.to_csv(DATA_FILE_NAME, index=False)\n",
        "\n",
        "print(f\"'{DATA_FILE_NAME}' created.\")\n",
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msd6he5NwOcG",
        "outputId": "f8ca177b-012e-45dd-bd50-2df5fa4a36f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "Adding my_s3_dataset.csv to cache:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
            "Adding my_s3_dataset.csv to cache:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
            "                                                                          \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 1/1 [00:00<00:00, 17.54file/s{'info': ''}]\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Cell 10: Add the dataset to DVC\n",
        "!dvc add $DATA_FILE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3Wk2DgwOcH"
      },
      "outputs": [],
      "source": [
        "# Cell 11: Commit the .dvc file to Git\n",
        "!git add my_s3_dataset.csv.dvc .gitignore # .gitignore might also be created by DVC\n",
        "!git commit -m \"Add initial S3 dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMnwsxAPwOcH"
      },
      "source": [
        "### Pushing Data to Amazon S3\n",
        "\n",
        "Now that DVC is tracking our `my_s3_dataset.csv` and Git knows about `my_s3_dataset.csv.dvc`, let's push the actual data to our Amazon S3 remote."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UaO4osBwOcH"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Push the DVC-tracked data to the remote (Amazon S3)\n",
        "# This will upload the cached data to your S3 bucket.\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28nikfghwOcH"
      },
      "source": [
        "### Simulating a New Session / New User\n",
        "\n",
        "Let's imagine you close this Colab notebook, or a teammate wants to work on your project. They would clone your Git repository and then `dvc pull` the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZLRdsF7wOcH"
      },
      "outputs": [],
      "source": [
        "# Cell 13: Simulate a clean environment (remove current data)\n",
        "# This will remove the symbolic link and the data itself from the workspace,\n",
        "# but the .dvc file and the data in cache/remote will remain.\n",
        "!rm $DATA_FILE_NAME\n",
        "\n",
        "# Verify it's gone\n",
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwAoJz6WwOcI"
      },
      "outputs": [],
      "source": [
        "# Cell 14: Pull the data back using DVC from S3\n",
        "!dvc pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqhQfTNCwOcI"
      },
      "outputs": [],
      "source": [
        "# Cell 15: Verify data is back\n",
        "!ls -lh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTtejLnywOcI"
      },
      "source": [
        "### Versioning Data Changes\n",
        "\n",
        "Let's modify our dataset and see how DVC helps us track the changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztb8B213wOcI"
      },
      "outputs": [],
      "source": [
        "# Cell 16: Modify the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the existing dataset\n",
        "df = pd.read_csv(DATA_FILE_NAME)\n",
        "\n",
        "# Add a new column\n",
        "df['new_s3_feature'] = df['feature1'] * df['feature2']\n",
        "\n",
        "# Save the modified dataset\n",
        "df.to_csv(DATA_FILE_NAME, index=False)\n",
        "\n",
        "print(f\"'{DATA_FILE_NAME}' modified.\")\n",
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx9wFLX2wOcI"
      },
      "outputs": [],
      "source": [
        "# Cell 17: Update DVC with the modified dataset\n",
        "!dvc add $DATA_FILE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11at5hZYwOcI"
      },
      "outputs": [],
      "source": [
        "# Cell 18: Commit the updated .dvc file to Git\n",
        "!git add my_s3_dataset.csv.dvc\n",
        "!git commit -m \"Update dataset with new_s3_feature\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_MAh-YNwOcJ"
      },
      "outputs": [],
      "source": [
        "# Cell 19: Push the updated data to the remote (S3)\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lk41ixcwOcJ"
      },
      "source": [
        "### Viewing Data History\n",
        "\n",
        "You can use `dvc status` and `dvc diff` to see the status of your DVC-tracked files and the differences between versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YubK6J19wOcJ"
      },
      "outputs": [],
      "source": [
        "# Cell 20: Check DVC status\n",
        "!dvc status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEUn0FUFwOcJ"
      },
      "source": [
        "## Real-Time Use Cases (Same as before, but with S3's benefits)\n",
        "\n",
        "The real-world use cases are fundamentally the same as with Google Drive (Reproducible ML Experiments, Collaborative Data Science, Model Deployment/Rollback), but S3 offers distinct advantages:\n",
        "\n",
        "* **Scalability:** S3 is designed for massive scale, handling petabytes of data, making it suitable for very large datasets and models.\n",
        "* **Performance:** Generally offers higher performance for data transfer compared to Google Drive, especially for programmatic access.\n",
        "* **Security & Access Control:** AWS IAM provides granular control over who can access your data and how. You can create specific policies for DVC users, services, or roles, ensuring strong security.\n",
        "* **Integration with AWS Ecosystem:** Seamless integration with other AWS services like EC2, SageMaker, Lambda, etc., which is beneficial if your ML pipeline is already heavily invested in AWS.\n",
        "* **Industry Standard:** S3 is a de-facto standard for cloud object storage in many enterprise and production environments.\n",
        "\n",
        "### Example: Reproducible ML Training with S3\n",
        "\n",
        "**Scenario:** An ML engineer is developing a model to forecast demand for an e-commerce platform. They need to experiment with different versions of historical sales data, and the data volumes are growing rapidly.\n",
        "\n",
        "**DVC (with S3) Application:**\n",
        "* **Data Ingestion:** Raw sales data is regularly uploaded to an S3 landing zone.\n",
        "* **Preprocessing:** A Colab notebook (or an AWS Glue/SageMaker processing job) processes this raw data, and the *processed version* is `dvc add`ed and `dvc push`ed to the DVC-specific S3 bucket.\n",
        "* **Model Training:** Different Colab notebooks (or EC2/SageMaker instances) can `dvc pull` specific versions of the processed data from S3, train models, and then `dvc add` and `dvc push` the resulting model artifacts (e.g., `model.pkl`, `evaluation_metrics.json`) back to the same S3 DVC remote.\n",
        "* **Version Control:** The Git repository tracks the code for data processing, model training, and the `.dvc` files that point to the data and model versions in S3.\n",
        "* **Reproducibility:** If a stakeholder asks, \"What data was used for Model v3.1?\", the engineer can `git checkout` the v3.1 commit and `dvc pull` to instantly retrieve the exact data and model that produced those results, directly from S3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsDVqgZewOcJ"
      },
      "source": [
        "## Hands-On Practice Tasks (with Amazon S3)\n",
        "\n",
        "These tasks are identical in concept to the Google Drive ones, but you'll be using your S3 remote.\n",
        "\n",
        "### Task 1: Create and Track a New Dataset (S3)\n",
        "\n",
        "1.  Create a new Python script (e.g., `generate_s3_data.py`) that generates a simple CSV file called `another_s3_dataset.csv` with 50 rows and 3 random columns.\n",
        "2.  Run the script to generate the file.\n",
        "3.  Use DVC to track `another_s3_dataset.csv`.\n",
        "4.  Commit the `.dvc` file to Git.\n",
        "5.  Push the actual data to your DVC Amazon S3 remote.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi0TaOSRwOcK"
      },
      "source": [
        "### Task 2: Simulate a Model Training Workflow (S3)\n",
        "\n",
        "1.  Create a dummy Python script named `train_s3_model.py`. This script should:\n",
        "    * Load `my_s3_dataset.csv`.\n",
        "    * Perform a simple \"model training\" (e.g., calculate the mean of the `target` column and save it to a text file named `s3_model_output.txt`).\n",
        "    * Save `s3_model_output.txt` in a new directory named `s3_models/`.\n",
        "2.  Run `train_s3_model.py`.\n",
        "3.  Track the `s3_models/` directory (and its contents) with DVC.\n",
        "4.  Commit the relevant `.dvc` file to Git.\n",
        "5.  Push the `s3_models/` directory content to your DVC Amazon S3 remote.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXBBDR0lwOcK"
      },
      "source": [
        "### Task 3: Revert Data to a Previous Version (S3)\n",
        "\n",
        "1.  Modify `my_s3_dataset.csv` again: add a fourth random column.\n",
        "2.  Track this modified dataset with DVC and commit its `.dvc` file to Git. Do *not* push the data to the remote yet.\n",
        "3.  Now, use Git and DVC to revert `my_s3_dataset.csv` back to its *first* version (the one without `new_s3_feature` or the fourth column).\n",
        "    * Hint: You will need to use `git log` to find the commit hash of the first dataset addition, then `git checkout` that commit, and finally `dvc pull`.\n",
        "4.  Verify that `my_s3_dataset.csv` indeed reverted to its original state (check its columns).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZ7pVi5wOcK"
      },
      "source": [
        "## Detailed Solutions with Explanations (for S3 Tasks)\n",
        "\n",
        "### Solution to Task 1: Create and Track a New Dataset (S3)\n",
        "\n",
        "**Explanation:**\n",
        "This is a direct application of the `dvc add`, `git add`, `git commit`, `dvc push` workflow, now pointing to S3.\n",
        "\n",
        "**Code:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4K4SbxFwOcK"
      },
      "outputs": [],
      "source": [
        "# Task 1: Create and Track a New Dataset (S3)\n",
        "\n",
        "# 1. Create a new Python script (e.g., generate_s3_data.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmu72Em9wOcK"
      },
      "outputs": [],
      "source": [
        "%%writefile generate_s3_data.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_data(num_rows=50):\n",
        "    data = {\n",
        "        f's3_col{i}': np.random.rand(num_rows) for i in range(1, 4)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('another_s3_dataset.csv', index=False)\n",
        "    print(\"Generated 'another_s3_dataset.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx_1PVYFwOcL"
      },
      "outputs": [],
      "source": [
        "# 2. Run the script to generate the file.\n",
        "!python generate_s3_data.py\n",
        "!ls -lh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaUomP7VwOcL"
      },
      "outputs": [],
      "source": [
        "# 3. Use DVC to track another_s3_dataset.csv.\n",
        "!dvc add another_s3_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZiIHGLawOcL"
      },
      "outputs": [],
      "source": [
        "# 4. Commit the .dvc file to Git.\n",
        "!git add another_s3_dataset.csv.dvc\n",
        "!git commit -m \"Add another_s3_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4D8M-DGwOcL"
      },
      "outputs": [],
      "source": [
        "# 5. Push the actual data to your DVC Amazon S3 remote.\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKUYZYcwOcR"
      },
      "source": [
        "### Solution to Task 2: Simulate a Model Training Workflow (S3)\n",
        "\n",
        "**Explanation:**\n",
        "Similar to the previous model tracking, but now the `s3_models/` directory and its contents will be stored in your S3 bucket.\n",
        "\n",
        "**Code:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5QOT9FewOcR"
      },
      "outputs": [],
      "source": [
        "# Task 2: Simulate a Model Training Workflow (S3)\n",
        "\n",
        "# 1. Create a dummy Python script named train_s3_model.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgKY-MwawOcR"
      },
      "outputs": [],
      "source": [
        "%%writefile train_s3_model.py\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def train_and_save_model(data_path='my_s3_dataset.csv', output_dir='s3_models/'):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "    # Simulate a simple \"model\" (e.g., calculating mean of a column)\n",
        "    target_mean = df['target'].mean()\n",
        "\n",
        "    model_output_path = os.path.join(output_dir, 's3_model_output.txt')\n",
        "    with open(model_output_path, 'w') as f:\n",
        "        f.write(f\"Mean of target column: {target_mean}\\n\")\n",
        "\n",
        "    print(f\"Model output saved to '{model_output_path}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-4y5avywOcS"
      },
      "outputs": [],
      "source": [
        "# 2. Run train_s3_model.py.\n",
        "!python train_s3_model.py\n",
        "!ls -lh\n",
        "!ls -lh s3_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NDogmh-wOcS"
      },
      "outputs": [],
      "source": [
        "# 3. Track the s3_models/ directory (and its contents) with DVC.\n",
        "!dvc add s3_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN88vOs2wOcS"
      },
      "outputs": [],
      "source": [
        "# 4. Commit the relevant .dvc file to Git.\n",
        "!git add s3_models.dvc\n",
        "!git commit -m \"Add trained S3 model output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnzruTyvwOcS"
      },
      "outputs": [],
      "source": [
        "# 5. Push the s3_models/ directory content to your DVC Amazon S3 remote.\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ1QvqhPwOcT"
      },
      "source": [
        "### Solution to Task 3: Revert Data to a Previous Version (S3)\n",
        "\n",
        "**Explanation:**\n",
        "This task reaffirms the Git+DVC revert mechanism, demonstrating that it works seamlessly regardless of the DVC remote type (Google Drive or S3). The core is `git checkout` to select the `.dvc` file version, followed by `dvc pull` to fetch the corresponding large data from S3.\n",
        "\n",
        "**Code:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL6eJRkJwOcT"
      },
      "outputs": [],
      "source": [
        "# Task 3: Revert Data to a Previous Version (S3)\n",
        "\n",
        "# 1. Modify my_s3_dataset.csv again: add a fourth random column.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(DATA_FILE_NAME)\n",
        "df['fourth_s3_feature'] = np.random.rand(len(df)) * 20\n",
        "df.to_csv(DATA_FILE_NAME, index=False)\n",
        "\n",
        "print(\"my_s3_dataset.csv modified with 'fourth_s3_feature'\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKjtS6urwOcT"
      },
      "outputs": [],
      "source": [
        "# 2. Track this modified dataset with DVC and commit its .dvc file to Git.\n",
        "# Do NOT push the data to the remote yet.\n",
        "!dvc add $DATA_FILE_NAME\n",
        "!git add my_s3_dataset.csv.dvc\n",
        "!git commit -m \"Add fourth_s3_feature to my_s3_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4__Jq0YwOcT"
      },
      "outputs": [],
      "source": [
        "# 3. Now, use Git and DVC to revert my_s3_dataset.csv back to its first version\n",
        "# (the one without new_s3_feature or the fourth column).\n",
        "\n",
        "# First, find the commit hash for \"Add initial S3 dataset\"\n",
        "# This will show you the commit history. Look for the message.\n",
        "!git log --oneline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qZjB4S4wOcT"
      },
      "outputs": [],
      "source": [
        "# Replace 'initial_s3_commit_hash' with the actual hash from your git log output\n",
        "# For example: initial_s3_commit_hash = 'abcdef1'\n",
        "initial_s3_commit_hash = 'YOUR_INITIAL_S3_COMMIT_HASH_HERE' # <--- REPLACE THIS\n",
        "\n",
        "# Checkout the specific Git commit\n",
        "!git checkout $initial_s3_commit_hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJKjHW_BwOcU"
      },
      "outputs": [],
      "source": [
        "# Now, pull the data associated with this commit using DVC\n",
        "!dvc pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAfygifDwOcU"
      },
      "outputs": [],
      "source": [
        "# 4. Verify that my_s3_dataset.csv indeed reverted to its original state.\n",
        "import pandas as pd\n",
        "\n",
        "df_reverted = pd.read_csv(DATA_FILE_NAME)\n",
        "print(df_reverted.head())\n",
        "print(f\"Columns after revert: {df_reverted.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9Djrp0TwOcU"
      },
      "outputs": [],
      "source": [
        "# Go back to the latest state of your master branch\n",
        "!git checkout master\n",
        "!dvc pull # Pull the latest data associated with the master branch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}